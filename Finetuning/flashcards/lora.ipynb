{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a4b6b66-7582-45ab-b0b7-b859db042e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments,GenerationConfig, AutoTokenizer, LlamaConfig\n",
    "from peft import LoraModel, LoraConfig, get_peft_model, PeftModel\n",
    "import pandas as pd\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import torch\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "import wandb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ee6407-c072-4323-87f8-10491fa78136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(test,model,tokenizer):\n",
    "    max_tokens = 2000\n",
    "    rouge = evaluate.load('rouge')\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    meteor = evaluate.load('meteor')\n",
    "    answers = list()\n",
    "    references = list()\n",
    "    for i,instance in enumerate(test):\n",
    "        prompt = instance['prompt']\n",
    "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        outputs = model.generate(\n",
    "                    inputs,max_length = max_tokens,\n",
    "                    pad_token_id=tokenizer.pad_token_id)\n",
    "        result = tokenizer.decode(outputs[0])[len(prompt)+3:-4]\n",
    "        answers.append(result)\n",
    "        references.append(instance['completion'])\n",
    "        if i % 100 == 0:\n",
    "            print(i,datetime.datetime.now())\n",
    "    bleu_score = bleu.compute(predictions = answers, references = references)\n",
    "    rouge_score = rouge.compute(predictions = answers, references = references)\n",
    "    meteor_score = meteor.compute(predictions = answers, references = references)\n",
    "    print(bleu_score)\n",
    "    print(rouge_score)\n",
    "    print(meteor_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6104f34-0a1f-413e-ac60-e18d8e80313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cfg():\n",
    "    config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        bias='none',\n",
    "        lora_dropout=0.1,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        use_rslora=True\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\",token = \"\",trust_remote_code = True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\",token = \"\",\n",
    "                                                torch_dtype=torch.float32,\n",
    "                                                 device_map='auto')\n",
    "  \n",
    "    \n",
    "    tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model = get_peft_model(model, config, \"default\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce078d9-342f-4c5b-a384-1fdd6884ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainer(train, test, model, tokenizer):\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"ft_April_2\",\n",
    "        auto_find_batch_size=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=50,\n",
    "        logging_steps=1,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.1,\n",
    "        bf16=False,\n",
    "        warmup_steps=70,\n",
    "        group_by_length=True,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        learning_rate=2e-4,\n",
    "        save_steps=8000,\n",
    "        fp16=False,\n",
    "        push_to_hub=False,\n",
    "        report_to=\"wandb\",\n",
    "        adam_beta2 = 0.95,\n",
    "        adam_epsilon = 1e-5,\n",
    "        #neftune_noise_alpha=5,\n",
    "        #remove_unused_columns=False\n",
    "    )\n",
    "    response_template = \"\\n[/INST]\"\n",
    "    response_template_ids = tokenizer.encode(response_template, add_special_tokens=False)[2:]\n",
    "    collator = DataCollatorForCompletionOnlyLM(response_template_ids, tokenizer=tokenizer,mlm=False)\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        args=args,\n",
    "        data_collator=collator,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=test,\n",
    "        packing=False,\n",
    "        max_seq_length=4096,\n",
    "        dataset_text_field='text',\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce165f69-77a2-462a-9640-ec4f74700f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = '''[INST] <<SYS>>\n",
    "Du är en hjälpsam medicinsk assistent som hjälper läkare och sjuksköterskor genom att sammanfatta information om patienter.\n",
    "Svara på svenska.\n",
    "<</SYS>>\n",
    "Nedan ges anamnes för en patient under en dag\n",
    "<anamnes>'''\n",
    "\n",
    "prompt2 = '''\n",
    "</anamnes>\n",
    "Du ska plocka ut information som passar i mallen nedan. Undvik onödig information och plocka endast ut sådant som rör varje rubrik. Om relevant information saknas så lämnar du rubriken tom.\n",
    "Formattera ditt svar enligt mallen. Ingen information kan finnas under flera rubriker.\n",
    "<mall>\n",
    "*Sjukdomshistoria (Patientens diagnoser, sjukdomshistorik och riskfaktorer (t.ex. sjukdomar i familjen))*\n",
    "\n",
    "*Sökorsaker (Patientens symtom och/eller datum för ingrepp)*\n",
    "\n",
    "*Åtgärder (Planerade undersökningar, behandlingar och åtgärder)*\n",
    "</mall>\n",
    "[/INST]'''\n",
    "data = pd.read_parquet(\"../../OpenAI/synthetic_5th_april.parquet\")\n",
    "#data2 = pd.read_parquet(\"../../OpenAI/synthetic_bertil.parquet\")\n",
    "#data3 = pd.read_parquet(\"../../OpenAI/synthetic_2nd.parquet\")\n",
    "#data4 = pd.read_parquet(\"../../OpenAI/synthetic_211.parquet\")\n",
    "\n",
    "#data = pd.concat([data1,data2,data3],ignore_index=True)\n",
    "\n",
    "formatted = []\n",
    "for index, row in data.iterrows():\n",
    "    #print(row)\n",
    "    elem = {'text':f\"<s> {prompt1}{row['description']}{prompt2} {row['summary']} </s>\"}\n",
    "    formatted.append(elem)\n",
    "    \n",
    "\n",
    "train, test = train_test_split(formatted,test_size = 0.05,random_state = 42)\n",
    "train = Dataset.from_list(train)\n",
    "test = Dataset.from_list(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3457fc04-62ad-41f6-a820-9bb205b54137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*Sjukdomshistoria*\n",
      "Diagnoser: Inga tidigare allvarliga sjukdomar.\n",
      "Riskfaktorer: Far med liknande symtom under medelåldern.\n",
      "\n",
      "*Sökorsaker*\n",
      "Känsla av att inte kunna hålla benen stilla, vilket förvärras på kvällen och påverkar sömnen.\n",
      "\n",
      "*Åtgärder*\n",
      "Påbörjad medicinsk behandling med dopaminagonist för Restless Legs Syndrome och återbesök om 6 veckor för uppföljning.\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[212]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7a5a6b-7dcc-47be-a1b4-a120694bf066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f53b42f83104166841d3aec315dcdab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177439010d314b8393389e1201d8bf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cb35cd43744e12b492c138c15e0571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00001204bfa34f82855a127c50cb2dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074759a9ea144e218ba1a959a962d001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = make_cfg()\n",
    "#compute_metrics(test,model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8408f7a7-ad0e-47bb-8159-a1388144293c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbae528b35d415e84607437afafa58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396b9a05eb7d43ccaedd39e4499a3802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 04:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlundalb\u001b[0m (\u001b[33mmaster-t\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/DATX05/Finetuning/flashcards/wandb/run-20240405_083630-8g5fy8r7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/master-t/huggingface/runs/8g5fy8r7' target=\"_blank\">nagus-frontier-24</a></strong> to <a href='https://wandb.ai/master-t/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/master-t/huggingface' target=\"_blank\">https://wandb.ai/master-t/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/master-t/huggingface/runs/8g5fy8r7' target=\"_blank\">https://wandb.ai/master-t/huggingface/runs/8g5fy8r7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='434' max='434' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [434/434 27:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.002900</td>\n",
       "      <td>0.642540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.804400</td>\n",
       "      <td>0.613558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.769600</td>\n",
       "      <td>0.601643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.583947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.629400</td>\n",
       "      <td>0.576450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.393400</td>\n",
       "      <td>0.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.235300</td>\n",
       "      <td>0.558035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:588: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-660fbee5-0facc39166eb3f4029514c05;5aeb7e23-f75f-48e5-9559-48433b27677b)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-13b-chat-hf/resolve/main/config.json.\n",
      "Repo model meta-llama/Llama-2-13b-chat-hf is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Llama-2-13b-chat-hf.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Llama-2-13b-chat-hf - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.026 MB of 0.026 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▂▂▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁████████▇</td></tr><tr><td>eval/steps_per_second</td><td>▁██████▇█▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▅▅▇███████▇▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▆▆▄▅▃▆▂▁█▅▂▄▄▄▄▃▂▃▄▃▂▄▃▄▂▄▅▃▂▄▂▁▇▂▃▃▄▆▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.55782</td></tr><tr><td>eval/runtime</td><td>41.494</td></tr><tr><td>eval/samples_per_second</td><td>0.554</td></tr><tr><td>eval/steps_per_second</td><td>0.072</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>434</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.1364</td></tr><tr><td>train/total_flos</td><td>3.330604539260928e+16</td></tr><tr><td>train/train_loss</td><td>0.67491</td></tr><tr><td>train/train_runtime</td><td>1684.7004</td></tr><tr><td>train/train_samples_per_second</td><td>0.258</td></tr><tr><td>train/train_steps_per_second</td><td>0.258</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">nagus-frontier-24</strong> at: <a href='https://wandb.ai/master-t/huggingface/runs/8g5fy8r7' target=\"_blank\">https://wandb.ai/master-t/huggingface/runs/8g5fy8r7</a><br/> View job at <a href='https://wandb.ai/master-t/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0ODc5MTUyOQ==/version_details/v12' target=\"_blank\">https://wandb.ai/master-t/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0ODc5MTUyOQ==/version_details/v12</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240405_083630-8g5fy8r7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = make_trainer(train,test,model, tokenizer)\n",
    "trainer.evaluate()\n",
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "trainer.save_model('../../../data/finetuned/lora_5th_apr_nodomain')\n",
    "#trainer.model.save_pretrained('../../../data/finetuned/lora_no_domain_adaptation/model')\n",
    "#trainer.tokenizer.save_pretrained('../../../data/finetuned/lora_no_domain_adaptation/tokenizer')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a30c2f-2177-4a72-8dda-9ef0d197a769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
